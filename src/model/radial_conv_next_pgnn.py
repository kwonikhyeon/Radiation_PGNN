#!/usr/bin/env python3
"""
Simplified ConvNeXt PGNN Architecture
ê¸°ì¡´ íŠ¹ì§•ì„ ìœ ì§€í•˜ë©´ì„œ ë³µì¡ì„±ì„ ëŒ€í­ ì¶•ì†Œí•œ ë²„ì „

Key Simplifications:
1. 4ê°œ ë¸Œëœì¹˜ â†’ 2ê°œ ë¸Œëœì¹˜ (Main + Confidence)
2. ë³µì¡í•œ suppression â†’ í•µì‹¬ 3ê°€ì§€ë§Œ
3. ê³¼ë„í•œ ì •ê·œí™” â†’ í•„ìˆ˜ ìš”ì†Œë§Œ
4. 99M â†’ ~50M íŒŒë¼ë¯¸í„° ëª©í‘œ

Preserved Features:
- ConvNeXt backbone
- Mask attention
- Physics-guided constraints
- Anti-blur mechanisms
- Adaptive scaling
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.models import create_model

class SimplifiedDecoderBlock(nn.Module):
    """ë‹¨ìˆœí™”ëœ ë””ì½”ë” ë¸”ë¡ - ê³µê°„ ì–´í…ì…˜ ì œê±°, í•µì‹¬ ê¸°ëŠ¥ë§Œ"""
    def __init__(self, in_c, skip_c, out_c):
        super().__init__()
        
        # ê°„ë‹¨í•œ skip connection ì²˜ë¦¬
        self.skip_conv = nn.Conv2d(skip_c, out_c//2, kernel_size=1) if skip_c > out_c else nn.Identity()
        skip_c_proc = out_c//2 if skip_c > out_c else skip_c
        
        # í•µì‹¬ convolutionë§Œ
        self.block = nn.Sequential(
            nn.Conv2d(in_c + skip_c_proc, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
        )

    def forward(self, x, skip):
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        if not isinstance(self.skip_conv, nn.Identity):
            skip = self.skip_conv(skip)
        
        x = torch.cat([x, skip], dim=1)
        x = self.block(x)
        return x


class SimplifiedConvNeXtPGNN(nn.Module):
    """
    ë‹¨ìˆœí™”ëœ ConvNeXt PGNN
    - 2ê°œ ë¸Œëœì¹˜: Main prediction + Confidence
    - í•µì‹¬ suppression ë©”ì»¤ë‹ˆì¦˜ë§Œ
    - ì•½ 50M íŒŒë¼ë¯¸í„° ëª©í‘œ
    """
    def __init__(self, in_channels=6, decoder_channels=[256, 128, 64, 32], pred_scale=1.0, enable_radial_guide=True):
        super().__init__()

        # ë” ì‘ì€ ConvNeXt ëª¨ë¸ ì‚¬ìš© (base â†’ small)
        self.encoder = create_model(
            "convnext_small",  # base â†’ smallë¡œ ë³€ê²½ (50M â†’ 25M)
            pretrained=False,
            features_only=True,
            in_chans=in_channels
        )

        enc_channels = [f['num_chs'] for f in self.encoder.feature_info]

        # ë‹¨ìˆœí™”ëœ ë§ˆìŠ¤í¬ ì–´í…ì…˜ (ì±„ë„ ìˆ˜ ë§ì¶¤)
        self.mask_proj = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(1, max(ch // 8, 16), kernel_size=3, padding=1),  # //4 â†’ //8
                nn.ReLU(inplace=True),
                nn.Conv2d(max(ch // 8, 16), ch, kernel_size=1)  # ì›ë³¸ ì±„ë„ ìˆ˜ì™€ ë§ì¶¤
            ) for ch in enc_channels
        ])

        # ë‹¨ìˆœí™”ëœ ë””ì½”ë” (ì±„ë„ ìˆ˜ ì ˆë°˜)
        self.up4 = SimplifiedDecoderBlock(enc_channels[3], enc_channels[2], decoder_channels[0])
        self.up3 = SimplifiedDecoderBlock(decoder_channels[0], enc_channels[1], decoder_channels[1])
        self.up2 = SimplifiedDecoderBlock(decoder_channels[1], enc_channels[0], decoder_channels[2])
        self.up1 = nn.Sequential(
            nn.Conv2d(decoder_channels[2], decoder_channels[3], kernel_size=3, padding=1),
            nn.BatchNorm2d(decoder_channels[3]),
            nn.ReLU(inplace=True),
        )

        # 2ê°œ ë¸Œëœì¹˜ë§Œ: Main + Confidence (ê¸°ì¡´ 4ê°œ â†’ 2ê°œ)
        self.main_head = nn.Sequential(
            nn.Conv2d(decoder_channels[3], 16, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 1, kernel_size=1)
        )
        
        self.confidence_head = nn.Sequential(
            nn.Conv2d(decoder_channels[3], 8, kernel_size=3, padding=1),  # 16 â†’ 8
            nn.ReLU(inplace=True),
            nn.Conv2d(8, 1, kernel_size=1),
            nn.Sigmoid()
        )
        
        # ë‹¨ìˆœí™”ëœ ì ì‘ì  ìŠ¤ì¼€ì¼ë§ (íŒŒë¼ë¯¸í„° ìˆ˜ ì¶•ì†Œ)
        self.adaptive_scale = nn.Parameter(torch.tensor(1.0))
        self.pred_scale = pred_scale
        
        # ì›í˜• ê°€ì´ë“œ ë ˆì´ì–´ ì¶”ê°€
        if enable_radial_guide:
            self.radial_guide = RadialBiasLayer(grid_size=256)
        else:
            self.radial_guide = None

    def forward(self, x):
        mask = x[:, 1:2]
        measured_values = x[:, 0:1]
        distance_map = x[:, 5:6]
        coord_x = x[:, 4:5]
        coord_y = x[:, 3:4]

        # ì¸ì½”ë”
        feats = self.encoder(x)
        feats_attn = []

        # ë‹¨ìˆœí™”ëœ ë§ˆìŠ¤í¬ ì–´í…ì…˜
        for f, attn_conv in zip(feats, self.mask_proj):
            mask_resized = F.interpolate(mask, size=f.shape[2:], mode='bilinear', align_corners=False)
            mask_feat = attn_conv(mask_resized)
            
            # ê°„ë‹¨í•œ ì–´í…ì…˜ (ë³µì¡í•œ ê³µì‹ ì œê±°)
            attention = torch.sigmoid(mask_feat) * 0.2
            feats_attn.append(f + attention)  # ê³±ì…ˆ ëŒ€ì‹  ë§ì…ˆë§Œ

        # ë””ì½”ë”
        c1, c2, c3, c4 = feats_attn
        u4 = self.up4(c4, c3)
        u3 = self.up3(u4, c2)
        u2 = self.up2(u3, c1)
        u1 = F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False)
        u1 = self.up1(u1)
        out = F.interpolate(u1, size=x.shape[2:], mode='bilinear', align_corners=False)
        
        # 2ê°œ ë¸Œëœì¹˜ ì˜ˆì¸¡
        main_pred = self.main_head(out)
        confidence = self.confidence_head(out)
        
        # ë‹¨ìˆœí™”ëœ ì ì‘ì  ìŠ¤ì¼€ì¼ë§
        B = x.shape[0]
        measured_max = torch.zeros(B, 1, 1, 1, device=x.device)
        
        for b in range(B):
            mask_b = mask[b, 0]
            if mask_b.sum() > 0:
                meas_vals = measured_values[b, 0][mask_b > 0]
                measured_max[b] = meas_vals.max() if len(meas_vals) > 0 else 1.0
            else:
                measured_max[b] = 1.0
        
        # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§
        scale_factor = 0.5 + 1.5 * torch.sigmoid(self.adaptive_scale * measured_max)
        
        # ê¸°ë³¸ ì˜ˆì¸¡ (unmeasured ì˜ì—­ë§Œ)
        pred_base = F.softplus(main_pred) * scale_factor * self.pred_scale
        
        # í•µì‹¬ 3ê°€ì§€ suppressionë§Œ ì ìš© (unmeasured ì˜ì—­ë§Œ)
        pred_suppressed = self.apply_core_suppression(pred_base, confidence, distance_map, mask, measured_values)
        
        # ğŸ”¥ í•µì‹¬: ì¸¡ì •ê°’ ì§ì ‘ ë³´ì¡´ (ìŠ¤íŒŒì´í¬ ë¬¸ì œ ì™„ì „ í•´ê²°)
        final_pred = self.preserve_measured_values(pred_suppressed, mask, measured_values)
        
        # ğŸ¯ ì›í˜• ë¶„í¬ ê°€ì´ë“œ ì ìš©
        if self.radial_guide is not None:
            source_locs = self.extract_source_locations(mask, measured_values)
            final_pred = self.radial_guide(final_pred, source_locs)
        
        return final_pred

    def apply_core_suppression(self, pred, confidence, distance_map, mask, measured_values):
        """í•µì‹¬ 3ê°€ì§€ suppression ë©”ì»¤ë‹ˆì¦˜ë§Œ ì ìš©"""
        
        # 1. ê±°ë¦¬ ê¸°ë°˜ ì–µì œ (í•µì‹¬)
        distance_suppression = torch.exp(-1.5 * distance_map)
        
        # 2. ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ì ˆ
        confidence_modulation = 0.5 + 0.4 * confidence  # [0.5, 0.9] ë²”ìœ„
        
        # 3. ì¸¡ì •ê°’ ë³´ì¡´ (ì†Œí”„íŠ¸ ì œì•½)
        measurement_preservation = 1.0 - 0.8 * mask  # ì¸¡ì • ì§€ì  ê·¼ì²˜ ì–µì œ ê°ì†Œ
        
        # ë‹¨ìˆœí•œ ê³±ì…ˆ ì¡°í•©
        suppression = distance_suppression * confidence_modulation * measurement_preservation
        pred_suppressed = pred * suppression
        
        # ê°•ë„ ì œí•œ (ì •ê·œí™”ëœ ë²”ìœ„ ì¤€ìˆ˜)
        # GTê°€ [0,1] ì •ê·œí™”ëœ ë²”ìœ„ì´ë¯€ë¡œ ì˜ˆì¸¡ë„ ë™ì¼ ë²”ìœ„ë¡œ ì œí•œ
        max_intensity = 1.0  # ì •ê·œí™”ëœ ìµœëŒ€ê°’
        pred_final = torch.clamp(pred_suppressed, min=0.0, max=max_intensity)
        
        return pred_final

    def preserve_measured_values(self, pred, mask, measured_values):
        """
        ğŸ”¥ í•µì‹¬: ì¸¡ì •ê°’ ì§ì ‘ ë³´ì¡´ìœ¼ë¡œ ìŠ¤íŒŒì´í¬ ì•„í‹°íŒ©íŠ¸ ì™„ì „ ì œê±°
        
        Args:
            pred: ëª¨ë¸ ì˜ˆì¸¡ê°’ [B, 1, H, W]
            mask: ì¸¡ì • ë§ˆìŠ¤í¬ [B, 1, H, W]
            measured_values: ì‹¤ì œ ì¸¡ì •ê°’ [B, 1, H, W]
        
        Returns:
            final_pred: ì¸¡ì •ì ì—ì„œ ì‹¤ì œê°’ ë³´ì¡´ëœ ìµœì¢… ì˜ˆì¸¡ [B, 1, H, W]
        """
        # ì¸¡ì •ì (mask=1)ì—ì„œëŠ” ì˜ˆì¸¡ê°’ ëŒ€ì‹  ì‹¤ì œ ì¸¡ì •ê°’ ì§ì ‘ ì‚¬ìš©
        # ë¹„ì¸¡ì •ì (mask=0)ì—ì„œëŠ” ëª¨ë¸ ì˜ˆì¸¡ê°’ ì‚¬ìš©
        final_pred = pred * (1 - mask) + measured_values * mask
        
        # ì„ íƒì : ì¸¡ì •ì  ì£¼ë³€ ë¶€ë“œëŸ¬ìš´ ì „í™˜ (optional smoothing)
        if hasattr(self, 'enable_measurement_smoothing') and self.enable_measurement_smoothing:
            final_pred = self._apply_measurement_smoothing(final_pred, pred, mask, measured_values)
        
        return final_pred
    
    def _apply_measurement_smoothing(self, final_pred, pred, mask, measured_values):
        """ì¸¡ì •ì  ì£¼ë³€ ë¶€ë“œëŸ¬ìš´ ì „í™˜ (ì„ íƒì  ê¸°ëŠ¥)"""
        # 3x3 ì»¤ë„ë¡œ ì¸¡ì •ì  ì£¼ë³€ ê°€ì¤‘ í‰ê· 
        kernel = torch.ones(1, 1, 3, 3, device=pred.device) / 9.0
        
        # ì¸¡ì •ì  ì£¼ë³€ ì˜ì—­ ì‹ë³„
        dilated_mask = F.conv2d(mask, kernel, padding=1)
        transition_mask = (dilated_mask > 0) & (dilated_mask < 1)  # ê²½ê³„ ì˜ì—­
        
        # ê²½ê³„ ì˜ì—­ì—ì„œ ê°€ì¤‘ í‰ê·  ì ìš©
        smoothed_pred = F.conv2d(final_pred, kernel, padding=1)
        
        # ê²½ê³„ ì˜ì—­ì—ë§Œ ë¶€ë“œëŸ¬ìš´ ì „í™˜ ì ìš©
        final_pred = final_pred * (1 - transition_mask.float()) + \
                    smoothed_pred * transition_mask.float()
        
        # ì¸¡ì •ì ì€ í•­ìƒ ì›ë³¸ê°’ ìœ ì§€
        final_pred = final_pred * (1 - mask) + measured_values * mask
        
        return final_pred
    
    def extract_source_locations(self, mask, measured_values):
        """ê°•í•œ ì¸¡ì •ê°’ ìœ„ì¹˜ ì¶”ì¶œ (ì›í˜• ê°€ì´ë“œìš©)"""
        source_locs = []
        B = mask.shape[0]
        
        for b in range(B):
            mask_b = mask[b, 0]
            meas_b = measured_values[b, 0]
            
            # ì„ê³„ê°’ ì´ìƒì¸ ì¸¡ì •ì ë“¤ ì°¾ê¸°
            strong_sources = torch.where((mask_b > 0) & (meas_b > 0.2))
            if len(strong_sources[0]) > 0:
                positions = torch.stack([strong_sources[0], strong_sources[1]], dim=1)
                intensities = meas_b[strong_sources]
                source_locs.append((positions, intensities))
            else:
                source_locs.append(None)
                
        return source_locs


class RadialBiasLayer(nn.Module):
    """ì›í˜• ë¶„í¬ë¥¼ ìœ ë„í•˜ëŠ” ë°”ì´ì–´ìŠ¤ ë ˆì´ì–´"""
    def __init__(self, grid_size=256, strength=0.3):
        super().__init__()
        self.strength = nn.Parameter(torch.tensor(strength))
        self.grid_size = grid_size
        
        # ì¤‘ì‹¬ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ ë§µ ìƒì„± (ì •ì  ë°”ì´ì–´ìŠ¤)
        y, x = torch.meshgrid(torch.arange(grid_size), torch.arange(grid_size), indexing='ij')
        center = grid_size // 2
        static_bias = torch.exp(-((x - center)**2 + (y - center)**2) / (grid_size**2 * 0.1))
        self.register_buffer('static_radial_bias', static_bias)
        
    def forward(self, pred, source_locations=None):
        """
        ì›í˜• ë°”ì´ì–´ìŠ¤ ì ìš©
        
        Args:
            pred: ëª¨ë¸ ì˜ˆì¸¡ê°’ [B, 1, H, W]
            source_locations: ê° ë°°ì¹˜ë³„ ì†ŒìŠ¤ ìœ„ì¹˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        B, C, H, W = pred.shape
        device = pred.device
        
        if source_locations is not None:
            # ë™ì  ì›í˜• ë°”ì´ì–´ìŠ¤ (ì†ŒìŠ¤ ìœ„ì¹˜ ê¸°ë°˜)
            bias = self.create_dynamic_bias(pred, source_locations)
        else:
            # ì •ì  ì›í˜• ë°”ì´ì–´ìŠ¤ (ì¤‘ì‹¬ ê¸°ì¤€)
            bias = self.static_radial_bias.unsqueeze(0).unsqueeze(0).expand(B, 1, -1, -1)
        
        # ì›í˜• ë°”ì´ì–´ìŠ¤ ì ìš© (ê³±ì…ˆìœ¼ë¡œ ì›í˜• í˜•íƒœ ê°•í™”)
        enhanced_pred = pred * (1.0 + self.strength * bias)
        
        return enhanced_pred
    
    def create_dynamic_bias(self, pred, source_locations):
        """ì†ŒìŠ¤ ìœ„ì¹˜ ê¸°ë°˜ ë™ì  ì›í˜• ë°”ì´ì–´ìŠ¤ ìƒì„±"""
        B, C, H, W = pred.shape
        device = pred.device
        
        # ì „ì²´ ë°”ì´ì–´ìŠ¤ ë§µ ì´ˆê¸°í™”
        bias_maps = torch.zeros(B, 1, H, W, device=device)
        
        for b, source_info in enumerate(source_locations):
            if source_info is None:
                # ì†ŒìŠ¤ê°€ ì—†ìœ¼ë©´ ì •ì  ë°”ì´ì–´ìŠ¤ ì‚¬ìš©
                bias_maps[b, 0] = self.static_radial_bias
                continue
                
            positions, intensities = source_info
            bias_map = torch.zeros(H, W, device=device)
            
            # ê° ì†ŒìŠ¤ì— ëŒ€í•´ ì›í˜• ë°”ì´ì–´ìŠ¤ ìƒì„±
            y_grid, x_grid = torch.meshgrid(torch.arange(H, device=device), 
                                           torch.arange(W, device=device), indexing='ij')
            
            for i, (pos, intensity) in enumerate(zip(positions, intensities)):
                sy, sx = pos[0].item(), pos[1].item()
                
                # í•´ë‹¹ ì†ŒìŠ¤ë¡œë¶€í„°ì˜ ê±°ë¦¬ ê³„ì‚°
                distances = torch.sqrt((y_grid - sy)**2 + (x_grid - sx)**2) + 1e-6
                
                # ì›í˜• ë°”ì´ì–´ìŠ¤ ìƒì„± (ê°€ìš°ì‹œì•ˆ í˜•íƒœ)
                sigma = min(H, W) * 0.2  # ì ì ˆí•œ í™•ì‚° ë²”ìœ„
                radial_bias = torch.exp(-(distances**2) / (2 * sigma**2))
                
                # ê°•ë„ì— ë¹„ë¡€í•˜ì—¬ ë°”ì´ì–´ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
                weight = intensity / intensities.max() if intensities.max() > 0 else 1.0
                bias_map += weight * radial_bias
            
            # ì •ê·œí™”
            if bias_map.max() > 0:
                bias_map = bias_map / bias_map.max()
            
            bias_maps[b, 0] = bias_map
        
        return bias_maps


def radial_physics_loss(pred: torch.Tensor, measured_values: torch.Tensor, 
                       mask: torch.Tensor, alpha=0.1) -> torch.Tensor:
    """ì›í˜• ë¶„í¬ë¥¼ ê°•ì œí•˜ëŠ” ë¬¼ë¦¬ ì†ì‹¤"""
    device = pred.device
    B, C, H, W = pred.shape
    total_loss = 0.0
    valid_samples = 0
    
    for b in range(B):
        pred_field = pred[b, 0]
        mask_b = mask[b, 0] 
        measured_b = measured_values[b, 0]
        
        # ì¸¡ì •ì ë“¤ì—ì„œ ì†ŒìŠ¤ ìœ„ì¹˜ ì¶”ì •
        source_positions = torch.where(mask_b > 0)
        if len(source_positions[0]) == 0:
            continue
            
        for i in range(len(source_positions[0])):
            sy, sx = source_positions[0][i].item(), source_positions[1][i].item()
            source_intensity = measured_b[sy, sx].item()
            
            if source_intensity > 0.1:  # ìœ ì˜ë¯¸í•œ ì†ŒìŠ¤ë§Œ
                # í•´ë‹¹ ì†ŒìŠ¤ë¡œë¶€í„°ì˜ ì´ë¡ ì  ì›í˜• ë¶„í¬ ê³„ì‚°
                y_grid, x_grid = torch.meshgrid(torch.arange(H, device=device), 
                                               torch.arange(W, device=device), indexing='ij')
                
                # ê±°ë¦¬ ê³„ì‚°
                distances = torch.sqrt((y_grid - sy)**2 + (x_grid - sx)**2) + 1e-6
                
                # ì´ë¡ ì  ì›í˜• ë¶„í¬ (ì—­ì œê³± ë²•ì¹™ + ì§€ìˆ˜ ê°ì‡ )
                theoretical = source_intensity * torch.exp(-distances / (min(H, W) * 0.3)) / (distances + 1.0)
                theoretical = torch.clamp(theoretical, min=0.0, max=source_intensity)
                
                # ì›í˜•ì„± ì†ì‹¤ (ì¸¡ì •ì  ì£¼ë³€ ì˜ì—­ë§Œ ê³ ë ¤)
                mask_region = (distances < min(H, W) * 0.4)  # ì˜í–¥ ë²”ìœ„ ì œí•œ
                
                if mask_region.sum() > 0:
                    radial_loss = F.mse_loss(pred_field[mask_region], theoretical[mask_region])
                    total_loss += radial_loss * alpha
                    valid_samples += 1
    
    return total_loss / max(valid_samples, 1) if valid_samples > 0 else torch.tensor(0.0, device=device)


def count_parameters(model):
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params


# ë¬¼ë¦¬ ì†ì‹¤ í•¨ìˆ˜ë“¤ë„ ë‹¨ìˆœí™”
def simplified_laplacian_loss(pred: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:
    """ë‹¨ìˆœí™”ëœ ë¼í”Œë¼ì‹œì•ˆ ì†ì‹¤"""
    # ê°„ë‹¨í•œ ë¼í”Œë¼ì‹œì•ˆ ì»¤ë„
    laplacian_kernel = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], 
                                  dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)
    
    laplacian = F.conv2d(pred, laplacian_kernel, padding=1)
    
    if mask is not None:
        # ì¸¡ì •ë˜ì§€ ì•Šì€ ì˜ì—­ì— ë” ê°•í•œ í‰í™œì„± ì ìš©
        weight = 1.0 + (1 - mask)
        return (weight * laplacian ** 2).mean()
    
    return (laplacian ** 2).mean()


def simplified_physics_loss(pred: torch.Tensor, gt: torch.Tensor, input_batch: torch.Tensor) -> torch.Tensor:
    """ë‹¨ìˆœí™”ëœ ë¬¼ë¦¬ ì†ì‹¤ (ê¸°ë³¸ ì—­ì œê³± ë²•ì¹™ë§Œ)"""
    device = pred.device
    B = pred.shape[0]
    
    # GTì—ì„œ ë‹¨ìˆœí•œ í”¼í¬ ì°¾ê¸°
    total_loss = 0.0
    valid_batches = 0
    
    for b in range(B):
        gt_field = gt[b, 0]
        mask = input_batch[b, 1]
        measured_vals = input_batch[b, 0]
        
        # ê°€ì¥ ë†’ì€ ê°’ë“¤ë§Œ ì†ŒìŠ¤ë¡œ ê°„ì£¼ (ë‹¨ìˆœí™”)
        if gt_field.max() > 0.2:
            # ê¸°ë³¸ì ì¸ ë¬¼ë¦¬ ì¼ê´€ì„±ë§Œ ì²´í¬
            physics_loss = F.mse_loss(pred[b] * mask, measured_vals.unsqueeze(0) * mask)
            total_loss += physics_loss
            valid_batches += 1
    
    return total_loss / max(valid_batches, 1)


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_simplified_model():
    """ë‹¨ìˆœí™”ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë‹¨ìˆœí™”ëœ ConvNeXt PGNN í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ëª¨ë¸ ìƒì„±
    model = SimplifiedConvNeXtPGNN(in_channels=6, pred_scale=1.0, enable_radial_guide=True)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    param_count = count_parameters(model)
    print(f"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {param_count:,} ({param_count/1e6:.1f}M)")
    
    # ìƒ˜í”Œ ì…ë ¥
    batch_size = 2
    input_tensor = torch.randn(batch_size, 6, 256, 256)
    
    # Forward pass í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        output = model(input_tensor)
    
    print(f"ì…ë ¥ í˜•íƒœ: {input_tensor.shape}")
    print(f"ì¶œë ¥ í˜•íƒœ: {output.shape}")
    print(f"ì¶œë ¥ ë²”ìœ„: [{output.min().item():.4f}, {output.max().item():.4f}]")
    print(f"ì¶œë ¥ í‰ê· : {output.mean().item():.4f}")
    print(f"ì¶œë ¥ í‘œì¤€í¸ì°¨: {output.std().item():.4f}")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
    model_size_mb = param_count * 4 / (1024**2)  # float32 ê¸°ì¤€
    print(f"ëª¨ë¸ í¬ê¸°: {model_size_mb:.1f} MB")
    
    return model


if __name__ == "__main__":
    model = test_simplified_model()