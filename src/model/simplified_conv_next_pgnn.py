#!/usr/bin/env python3
"""
Simplified ConvNeXt PGNN Architecture
ê¸°ì¡´ íŠ¹ì§•ì„ ìœ ì§€í•˜ë©´ì„œ ë³µì¡ì„±ì„ ëŒ€í­ ì¶•ì†Œí•œ ë²„ì „

Key Simplifications:
1. 4ê°œ ë¸Œëœì¹˜ â†’ 2ê°œ ë¸Œëœì¹˜ (Main + Confidence)
2. ë³µì¡í•œ suppression â†’ í•µì‹¬ 3ê°€ì§€ë§Œ
3. ê³¼ë„í•œ ì •ê·œí™” â†’ í•„ìˆ˜ ìš”ì†Œë§Œ
4. 99M â†’ ~50M íŒŒë¼ë¯¸í„° ëª©í‘œ

Preserved Features:
- ConvNeXt backbone
- Mask attention
- Physics-guided constraints
- Anti-blur mechanisms
- Adaptive scaling
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from timm.models import create_model

class SimplifiedDecoderBlock(nn.Module):
    """ë‹¨ìˆœí™”ëœ ë””ì½”ë” ë¸”ë¡ - ê³µê°„ ì–´í…ì…˜ ì œê±°, í•µì‹¬ ê¸°ëŠ¥ë§Œ"""
    def __init__(self, in_c, skip_c, out_c):
        super().__init__()
        
        # ê°„ë‹¨í•œ skip connection ì²˜ë¦¬
        self.skip_conv = nn.Conv2d(skip_c, out_c//2, kernel_size=1) if skip_c > out_c else nn.Identity()
        skip_c_proc = out_c//2 if skip_c > out_c else skip_c
        
        # í•µì‹¬ convolutionë§Œ
        self.block = nn.Sequential(
            nn.Conv2d(in_c + skip_c_proc, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
        )

    def forward(self, x, skip):
        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)
        
        if not isinstance(self.skip_conv, nn.Identity):
            skip = self.skip_conv(skip)
        
        x = torch.cat([x, skip], dim=1)
        x = self.block(x)
        return x


class SimplifiedConvNeXtPGNN(nn.Module):
    """
    ë‹¨ìˆœí™”ëœ ConvNeXt PGNN
    - 2ê°œ ë¸Œëœì¹˜: Main prediction + Confidence
    - í•µì‹¬ suppression ë©”ì»¤ë‹ˆì¦˜ë§Œ
    - ì•½ 50M íŒŒë¼ë¯¸í„° ëª©í‘œ
    """
    def __init__(self, in_channels=6, decoder_channels=[256, 128, 64, 32], pred_scale=1.0):
        super().__init__()

        # ë” ì‘ì€ ConvNeXt ëª¨ë¸ ì‚¬ìš© (base â†’ small)
        self.encoder = create_model(
            "convnext_small",  # base â†’ smallë¡œ ë³€ê²½ (50M â†’ 25M)
            pretrained=False,
            features_only=True,
            in_chans=in_channels
        )

        enc_channels = [f['num_chs'] for f in self.encoder.feature_info]

        # ë‹¨ìˆœí™”ëœ ë§ˆìŠ¤í¬ ì–´í…ì…˜ (ì±„ë„ ìˆ˜ ë§ì¶¤)
        self.mask_proj = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(1, max(ch // 8, 16), kernel_size=3, padding=1),  # //4 â†’ //8
                nn.ReLU(inplace=True),
                nn.Conv2d(max(ch // 8, 16), ch, kernel_size=1)  # ì›ë³¸ ì±„ë„ ìˆ˜ì™€ ë§ì¶¤
            ) for ch in enc_channels
        ])

        # ë‹¨ìˆœí™”ëœ ë””ì½”ë” (ì±„ë„ ìˆ˜ ì ˆë°˜)
        self.up4 = SimplifiedDecoderBlock(enc_channels[3], enc_channels[2], decoder_channels[0])
        self.up3 = SimplifiedDecoderBlock(decoder_channels[0], enc_channels[1], decoder_channels[1])
        self.up2 = SimplifiedDecoderBlock(decoder_channels[1], enc_channels[0], decoder_channels[2])
        self.up1 = nn.Sequential(
            nn.Conv2d(decoder_channels[2], decoder_channels[3], kernel_size=3, padding=1),
            nn.BatchNorm2d(decoder_channels[3]),
            nn.ReLU(inplace=True),
        )

        # 2ê°œ ë¸Œëœì¹˜ë§Œ: Main + Confidence (ê¸°ì¡´ 4ê°œ â†’ 2ê°œ)
        self.main_head = nn.Sequential(
            nn.Conv2d(decoder_channels[3], 16, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(16, 1, kernel_size=1)
        )
        
        self.confidence_head = nn.Sequential(
            nn.Conv2d(decoder_channels[3], 8, kernel_size=3, padding=1),  # 16 â†’ 8
            nn.ReLU(inplace=True),
            nn.Conv2d(8, 1, kernel_size=1),
            nn.Sigmoid()
        )
        
        # ë‹¨ìˆœí™”ëœ ì ì‘ì  ìŠ¤ì¼€ì¼ë§ (íŒŒë¼ë¯¸í„° ìˆ˜ ì¶•ì†Œ)
        self.adaptive_scale = nn.Parameter(torch.tensor(1.0))
        self.pred_scale = pred_scale

    def forward(self, x):
        mask = x[:, 1:2]
        measured_values = x[:, 0:1]
        distance_map = x[:, 5:6]
        coord_x = x[:, 4:5]
        coord_y = x[:, 3:4]

        # ì¸ì½”ë”
        feats = self.encoder(x)
        feats_attn = []

        # ë‹¨ìˆœí™”ëœ ë§ˆìŠ¤í¬ ì–´í…ì…˜
        for f, attn_conv in zip(feats, self.mask_proj):
            mask_resized = F.interpolate(mask, size=f.shape[2:], mode='bilinear', align_corners=False)
            mask_feat = attn_conv(mask_resized)
            
            # ê°„ë‹¨í•œ ì–´í…ì…˜ (ë³µì¡í•œ ê³µì‹ ì œê±°)
            attention = torch.sigmoid(mask_feat) * 0.2
            feats_attn.append(f + attention)  # ê³±ì…ˆ ëŒ€ì‹  ë§ì…ˆë§Œ

        # ë””ì½”ë”
        c1, c2, c3, c4 = feats_attn
        u4 = self.up4(c4, c3)
        u3 = self.up3(u4, c2)
        u2 = self.up2(u3, c1)
        u1 = F.interpolate(u2, scale_factor=2, mode='bilinear', align_corners=False)
        u1 = self.up1(u1)
        out = F.interpolate(u1, size=x.shape[2:], mode='bilinear', align_corners=False)
        
        # 2ê°œ ë¸Œëœì¹˜ ì˜ˆì¸¡
        main_pred = self.main_head(out)
        confidence = self.confidence_head(out)
        
        # ë‹¨ìˆœí™”ëœ ì ì‘ì  ìŠ¤ì¼€ì¼ë§
        B = x.shape[0]
        measured_max = torch.zeros(B, 1, 1, 1, device=x.device)
        
        for b in range(B):
            mask_b = mask[b, 0]
            if mask_b.sum() > 0:
                meas_vals = measured_values[b, 0][mask_b > 0]
                measured_max[b] = meas_vals.max() if len(meas_vals) > 0 else 1.0
            else:
                measured_max[b] = 1.0
        
        # ê°„ë‹¨í•œ ìŠ¤ì¼€ì¼ë§
        scale_factor = 0.5 + 1.5 * torch.sigmoid(self.adaptive_scale * measured_max)
        
        # ê¸°ë³¸ ì˜ˆì¸¡
        pred_base = F.softplus(main_pred) * scale_factor * self.pred_scale
        
        # í•µì‹¬ 3ê°€ì§€ suppressionë§Œ ì ìš©
        final_pred = self.apply_core_suppression(pred_base, confidence, distance_map, mask, measured_values)
        
        return final_pred

    def apply_core_suppression(self, pred, confidence, distance_map, mask, measured_values):
        """í•µì‹¬ 3ê°€ì§€ suppression ë©”ì»¤ë‹ˆì¦˜ë§Œ ì ìš©"""
        
        # 1. ê±°ë¦¬ ê¸°ë°˜ ì–µì œ (í•µì‹¬)
        distance_suppression = torch.exp(-1.5 * distance_map)
        
        # 2. ì‹ ë¢°ë„ ê¸°ë°˜ ì¡°ì ˆ
        confidence_modulation = 0.5 + 0.4 * confidence  # [0.5, 0.9] ë²”ìœ„
        
        # 3. ì¸¡ì •ê°’ ë³´ì¡´ (ì†Œí”„íŠ¸ ì œì•½)
        measurement_preservation = 1.0 - 0.8 * mask  # ì¸¡ì • ì§€ì  ê·¼ì²˜ ì–µì œ ê°ì†Œ
        
        # ë‹¨ìˆœí•œ ê³±ì…ˆ ì¡°í•©
        suppression = distance_suppression * confidence_modulation * measurement_preservation
        pred_suppressed = pred * suppression
        
        # ê°•ë„ ì œí•œ (ê°„ë‹¨í•œ í´ë¦¬í•‘)
        max_intensity = measured_values.max() * 2.0  # 2ë°° ì œí•œ
        pred_final = torch.clamp(pred_suppressed, max=max_intensity)
        
        return pred_final


def count_parameters(model):
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params


# ë¬¼ë¦¬ ì†ì‹¤ í•¨ìˆ˜ë“¤ë„ ë‹¨ìˆœí™”
def simplified_laplacian_loss(pred: torch.Tensor, mask: torch.Tensor = None) -> torch.Tensor:
    """ë‹¨ìˆœí™”ëœ ë¼í”Œë¼ì‹œì•ˆ ì†ì‹¤"""
    # ê°„ë‹¨í•œ ë¼í”Œë¼ì‹œì•ˆ ì»¤ë„
    laplacian_kernel = torch.tensor([[0, -1, 0], [-1, 4, -1], [0, -1, 0]], 
                                  dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)
    
    laplacian = F.conv2d(pred, laplacian_kernel, padding=1)
    
    if mask is not None:
        # ì¸¡ì •ë˜ì§€ ì•Šì€ ì˜ì—­ì— ë” ê°•í•œ í‰í™œì„± ì ìš©
        weight = 1.0 + (1 - mask)
        return (weight * laplacian ** 2).mean()
    
    return (laplacian ** 2).mean()


def simplified_physics_loss(pred: torch.Tensor, gt: torch.Tensor, input_batch: torch.Tensor) -> torch.Tensor:
    """ë‹¨ìˆœí™”ëœ ë¬¼ë¦¬ ì†ì‹¤ (ê¸°ë³¸ ì—­ì œê³± ë²•ì¹™ë§Œ)"""
    device = pred.device
    B = pred.shape[0]
    
    # GTì—ì„œ ë‹¨ìˆœí•œ í”¼í¬ ì°¾ê¸°
    total_loss = 0.0
    valid_batches = 0
    
    for b in range(B):
        gt_field = gt[b, 0]
        mask = input_batch[b, 1]
        measured_vals = input_batch[b, 0]
        
        # ê°€ì¥ ë†’ì€ ê°’ë“¤ë§Œ ì†ŒìŠ¤ë¡œ ê°„ì£¼ (ë‹¨ìˆœí™”)
        if gt_field.max() > 0.2:
            # ê¸°ë³¸ì ì¸ ë¬¼ë¦¬ ì¼ê´€ì„±ë§Œ ì²´í¬
            physics_loss = F.mse_loss(pred[b] * mask, measured_vals.unsqueeze(0) * mask)
            total_loss += physics_loss
            valid_batches += 1
    
    return total_loss / max(valid_batches, 1)


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_simplified_model():
    """ë‹¨ìˆœí™”ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë‹¨ìˆœí™”ëœ ConvNeXt PGNN í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ëª¨ë¸ ìƒì„±
    model = SimplifiedConvNeXtPGNN(in_channels=6, pred_scale=1.0)
    
    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
    param_count = count_parameters(model)
    print(f"ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {param_count:,} ({param_count/1e6:.1f}M)")
    
    # ìƒ˜í”Œ ì…ë ¥
    batch_size = 2
    input_tensor = torch.randn(batch_size, 6, 256, 256)
    
    # Forward pass í…ŒìŠ¤íŠ¸
    with torch.no_grad():
        output = model(input_tensor)
    
    print(f"ì…ë ¥ í˜•íƒœ: {input_tensor.shape}")
    print(f"ì¶œë ¥ í˜•íƒœ: {output.shape}")
    print(f"ì¶œë ¥ ë²”ìœ„: [{output.min().item():.4f}, {output.max().item():.4f}]")
    print(f"ì¶œë ¥ í‰ê· : {output.mean().item():.4f}")
    print(f"ì¶œë ¥ í‘œì¤€í¸ì°¨: {output.std().item():.4f}")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
    model_size_mb = param_count * 4 / (1024**2)  # float32 ê¸°ì¤€
    print(f"ëª¨ë¸ í¬ê¸°: {model_size_mb:.1f} MB")
    
    return model


if __name__ == "__main__":
    model = test_simplified_model()