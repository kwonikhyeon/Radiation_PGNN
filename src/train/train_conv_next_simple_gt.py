#!/usr/bin/env python3
"""
Simplified ConvNeXt PGNN Training Script
ë‹¨ìˆœí™”ëœ ConvNeXt PGNN (53M íŒŒë¼ë¯¸í„°) í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
- ê¸°ì¡´ 99M â†’ 53M íŒŒë¼ë¯¸í„°ë¡œ ë³µì¡ì„± ê°ì†Œ
- Saturation ë¬¸ì œ í•´ê²°ëœ ì•ˆì •ì ì¸ ì•„í‚¤í…ì²˜
- GT-Physics ì†ì‹¤ í¬í•¨
"""
import argparse, json, pathlib, sys
from pathlib import Path

import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì •
ROOT = pathlib.Path(__file__).resolve().parents[1]
sys.path.append(str(ROOT))  

# ë‹¨ìˆœí™”ëœ ëª¨ë¸ ì„í¬íŠ¸
try:
    from model.simplified_conv_next_pgnn import (
        SimplifiedConvNeXtPGNN,
        simplified_laplacian_loss,
        simplified_physics_loss
    )
    print(f"âœ… Successfully imported SimplifiedConvNeXtPGNN from {ROOT}")
except ImportError as e:
    print(f"âŒ Error importing simplified model: {e}")
    print(f"Current ROOT path: {ROOT}")
    print(f"Simplified model file exists: {(ROOT / 'simplified_conv_next_pgnn.py').exists()}")
    sys.exit(1)

# GT-Physics ê´€ë ¨ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ëª¨ë“ˆì—ì„œ ê°€ì ¸ì˜¤ê¸°)
sys.path.append(str(pathlib.Path(__file__).resolve().parents[1]))
from model.conv_next_pgnn import (
    gt_based_inverse_square_law_loss,
    extract_measured_data
)

class RadFieldDataset(Dataset):
    def __init__(self, npz_path: Path):
        self.data = np.load(npz_path)
        if "inp" in self.data:
            self.inp = self.data["inp"].astype(np.float32)
        else:
            chans = [self.data[k].astype(np.float32)
                      for k in ["M", "mask", "logM", "X", "Y", "distance"]]
            self.inp = np.stack(chans, axis=1)
        self.gt  = self.data["gt"].astype(np.float32)
        self.names = [f"{npz_path.stem}_{i}" for i in range(len(self.inp))]

    def __len__(self):  return len(self.inp)

    def __getitem__(self, idx):
        return ( torch.from_numpy(self.inp[idx]),
                 torch.from_numpy(self.gt[idx]),
                 self.names[idx] )

from kornia.metrics import ssim as kornia_ssim

def ssim(pred, gt):
    try:
        return kornia_ssim(pred, gt, window_size=11, reduction="none").mean()
    except TypeError:
        return kornia_ssim(pred, gt, window_size=11).mean()

def train_one_epoch_simple_gt(model, loader, optimizer, epoch, cfg):
    """Simplified ConvNeXt PGNN + GT-Physics í›ˆë ¨ í•¨ìˆ˜"""
    model.train()
    losses = []
    ssims = []
    
    pbar = tqdm(loader, desc=f"Epoch {epoch:3d}")
    for batch_idx, (inp, gt, names) in enumerate(pbar):
        inp, gt = inp.to(cfg.device), gt.to(cfg.device)
        
        optimizer.zero_grad()
        
        mask = inp[:, 1:2]  # measurement mask
        pred = model(inp)   # [B, 1, H, W]

        # 1. CORE LOSS: Basic reconstruction with distance weighting
        dist = inp[:, 5:6]
        weight = torch.exp(-2.0 * dist)
        
        unmeasured_mask = (1 - mask)
        loss_unmeasured = F.mse_loss(
            pred * unmeasured_mask * weight, 
            gt * unmeasured_mask * weight
        )
        
        loss_all = F.mse_loss(pred, gt)
        
        # 2. MEASUREMENT CONSTRAINT LOSS (ê°„ì†Œí™”ë¨ - ì§ì ‘ ë³´ì¡´ìœ¼ë¡œ ì¸í•´)
        mask_float = mask.float()
        measured_values = inp[:, 0:1]
        
        # ğŸ”¥ í•µì‹¬ ë³€ê²½: ì¸¡ì •ê°’ ì§ì ‘ ë³´ì¡´ìœ¼ë¡œ ì¸í•´ ì¸¡ì •ì  ì†ì‹¤ ëŒ€í­ ê°„ì†Œí™”
        # ì¸¡ì •ì ì—ì„œëŠ” ì´ë¯¸ ì •í™•í•œ ê°’ì´ ë³´ì¡´ë˜ë¯€ë¡œ ë³„ë„ ì œì•½ ë¶ˆí•„ìš”
        
        # A. ì¸¡ì •ì  ë³´ì¡´ í™•ì¸ (ë””ë²„ê¹…ìš©, ì‹¤ì œë¡œëŠ” í•­ìƒ 0ì´ì–´ì•¼ í•¨)
        measurement_preservation_check = F.mse_loss(pred * mask_float, measured_values * mask_float)
        
        # B. ì¸¡ì •ê°’ ìŠ¤íŒŒì´í¬ ì–µì œ ì†ì‹¤ ì œê±° (ì§ì ‘ ë³´ì¡´ìœ¼ë¡œ í•´ê²°ë¨)
        spike_penalty = torch.tensor(0.0, device=cfg.device)
        
        # 3. PHYSICS LOSS: Laplacian smoothness (ì ì§„ì  ì ìš©) - ë‹¨ìˆœí™”ëœ ë²„ì „ ì‚¬ìš©
        if epoch >= 5:
            lambda_pg = min(0.05, (epoch - 5) / 20.0 * 0.05)
            lap_loss = simplified_laplacian_loss(pred, mask)
        else:
            lambda_pg = 0.0
            lap_loss = torch.tensor(0.0, device=cfg.device)
        
        # 4. GT-PHYSICS LOSS (í•µì‹¬ ì¶”ê°€!) 
        gt_physics_loss = torch.tensor(0.0, device=cfg.device)
        if epoch >= cfg.gt_physics_start_epoch and cfg.use_gt_physics:
            try:
                # ì¸¡ì • ë°ì´í„° ì¶”ì¶œ
                measured_positions, measured_values_list = extract_measured_data(inp)
                
                # GT ê¸°ë°˜ ë¬¼ë¦¬ ì†ì‹¤ ê³„ì‚°
                gt_physics_loss = gt_based_inverse_square_law_loss(
                    pred, gt, measured_positions, measured_values_list,
                    background_level=cfg.background_level,
                    beta=cfg.air_attenuation
                )
                
                # ì•ˆì „ ì¥ì¹˜
                if torch.isnan(gt_physics_loss) or torch.isinf(gt_physics_loss):
                    gt_physics_loss = torch.tensor(0.0, device=cfg.device)
                elif gt_physics_loss > 5.0:
                    gt_physics_loss = torch.clamp(gt_physics_loss, max=5.0)
                    
                # ì ì§„ì  ê°€ì¤‘ì¹˜ ì¦ê°€
                lambda_gt_physics = min(cfg.gt_physics_weight, 
                                      (epoch - cfg.gt_physics_start_epoch) / cfg.gt_physics_warmup * cfg.gt_physics_weight)
            except Exception as e:
                # print(f"GT-Physics loss calculation failed: {e}")
                gt_physics_loss = torch.tensor(0.0, device=cfg.device)
                lambda_gt_physics = 0.0
        else:
            lambda_gt_physics = 0.0
        
        # 5. ê°€ìš°ì‹œì•ˆ í˜•íƒœ ì œì•½ (ì†ŒìŠ¤ í™•ì‚° ë°©ì§€)
        gaussian_loss = torch.tensor(0.0, device=cfg.device)
        if epoch >= 10:  # ì–´ëŠì •ë„ í•™ìŠµ í›„ ì ìš©
            # GTì—ì„œ í”¼í¬ ìœ„ì¹˜ ì°¾ê¸°
            B = gt.shape[0]
            for b in range(B):
                gt_b = gt[b, 0]  # [H, W]
                pred_b = pred[b, 0]  # [H, W]
                
                if gt_b.max() > 0.5:  # ìœ ì˜ë¯¸í•œ ì†ŒìŠ¤ê°€ ìˆëŠ” ê²½ìš°
                    # GT í”¼í¬ ìœ„ì¹˜
                    peak_idx = torch.argmax(gt_b.flatten())
                    peak_y, peak_x = peak_idx // gt_b.shape[1], peak_idx % gt_b.shape[1]
                    
                    # í”¼í¬ ì£¼ë³€ ì˜ì—­ ì •ì˜ (15x15)
                    y_min, y_max = max(0, peak_y-7), min(gt_b.shape[0], peak_y+8)
                    x_min, x_max = max(0, peak_x-7), min(gt_b.shape[1], peak_x+8)
                    
                    # í•´ë‹¹ ì˜ì—­ì—ì„œ ê°€ìš°ì‹œì•ˆ í˜•íƒœ ìœ ë„
                    pred_region = pred_b[y_min:y_max, x_min:x_max]
                    gt_region = gt_b[y_min:y_max, x_min:x_max]
                    
                    # ì¤‘ì‹¬ì—ì„œ ê±°ë¦¬ë³„ ê°€ì¤‘ì¹˜ (ê°€ìš°ì‹œì•ˆ ê°ì‡  ìœ ë„)
                    center_y, center_x = pred_region.shape[0]//2, pred_region.shape[1]//2
                    y_coords, x_coords = torch.meshgrid(
                        torch.arange(pred_region.shape[0], device=cfg.device),
                        torch.arange(pred_region.shape[1], device=cfg.device),
                        indexing='ij'
                    )
                    distances = torch.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)
                    
                    # ê±°ë¦¬ì— ë”°ë¥¸ ê°ì‡  ë¹„ìœ¨ì´ GTì™€ ìœ ì‚¬í•´ì•¼ í•¨
                    if gt_region.max() > 0:
                        gt_decay = gt_region / gt_region.max()
                        pred_decay = pred_region / (pred_region.max() + 1e-8)
                        
                        # ë¨¼ ê±°ë¦¬ì—ì„œì˜ ê°ì‡ ê°€ GTì™€ ìœ ì‚¬í•´ì•¼ í•¨
                        far_mask = (distances > 3.0).float()
                        gaussian_loss += F.mse_loss(pred_decay * far_mask, gt_decay * far_mask) / B
        
        # 6. ê°•ë„ ì œí•œ ì†ì‹¤ (ì •ê·œí™”ëœ ë²”ìœ„ ì¤€ìˆ˜)
        intensity_limit_loss = torch.tensor(0.0, device=cfg.device)
        if epoch >= 5:
            # GTê°€ [0,1] ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì˜ˆì¸¡ë„ ë™ì¼ ë²”ìœ„ë¡œ ì œí•œ
            intensity_penalty = F.relu(pred - 1.0).mean()  # 1.0 ì´ìƒ ì–µì œ (1.5â†’1.0)
            
            # í”¼í¬ ì£¼ë³€ì´ ì•„ë‹Œ ê³³ì—ì„œ ê°•í•œ ì˜ˆì¸¡ ì–µì œ
            for b in range(gt.shape[0]):
                gt_b = gt[b, 0]
                pred_b = pred[b, 0]
                
                if gt_b.max() > 0.3:
                    # GT í”¼í¬ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ ê³³ì˜ ê°•í•œ ì˜ˆì¸¡ ì–µì œ
                    peak_idx = torch.argmax(gt_b.flatten())
                    peak_y, peak_x = peak_idx // gt_b.shape[1], peak_idx % gt_b.shape[1]
                    
                    y_coords, x_coords = torch.meshgrid(
                        torch.arange(gt_b.shape[0], device=cfg.device),
                        torch.arange(gt_b.shape[1], device=cfg.device),
                        indexing='ij'
                    )
                    distances = torch.sqrt((y_coords - peak_y)**2 + (x_coords - peak_x)**2)
                    
                    # í”¼í¬ì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ ê³³ (ê±°ë¦¬ > 20)ì—ì„œ ê°•í•œ ì˜ˆì¸¡ ì–µì œ
                    far_region = (distances > 20.0).float()
                    intensity_limit_loss += F.relu(pred_b * far_region - 0.05).mean() / gt.shape[0]  # 0.1â†’0.05
        
        # 7. TOTAL LOSS (ì§ì ‘ ì¸¡ì •ê°’ ë³´ì¡´ ë²„ì „ - ëŒ€í­ ê°„ì†Œí™”)
        loss = (
            3.0 * loss_unmeasured +                           # ì£¼ìš” ì¬êµ¬ì„± (ì¦ê°€: 2.0â†’3.0)
            0.5 * loss_all +                                  # ì „ì²´ ì¬êµ¬ì„± (ì¦ê°€: 0.3â†’0.5)
            10.0 * measurement_preservation_check +           # ì¸¡ì •ê°’ ë³´ì¡´ í™•ì¸ (ëŒ€í­ ê°ì†Œ: 500â†’10)
            0.0 * spike_penalty +                             # ìŠ¤íŒŒì´í¬ ì–µì œ ì œê±° (100â†’0)
            lambda_pg * lap_loss +                            # ë¼í”Œë¼ì‹œì•ˆ (ì ì§„ì )
            lambda_gt_physics * gt_physics_loss +             # GT-Physics (ì ì§„ì )
            0.3 * gaussian_loss +                             # ê°€ìš°ì‹œì•ˆ í˜•íƒœ ì œì•½ (ì¦ê°€: 0.2â†’0.3)
            0.7 * intensity_limit_loss                        # ê°•ë„ ì œí•œ (ì¦ê°€: 0.5â†’0.7)
        )
        
        # ì•ˆì „ ì¥ì¹˜
        if torch.isnan(loss) or torch.isinf(loss) or loss > 50.0:
            print(f"Warning: Abnormal loss {loss:.4f} at epoch {epoch}, batch {batch_idx}")
            continue
        
        loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        losses.append(loss.item())
        
        # SSIM ê³„ì‚°
        with torch.no_grad():
            ssim_val = ssim(pred, gt).item()
            ssims.append(ssim_val)
        
        # ì§„í–‰ë¥  í‘œì‹œ
        pbar.set_postfix({
            "Loss": f"{loss.item():.4f}",
            "SSIM": f"{ssim_val:.4f}",
            "LapW": f"{lambda_pg:.4f}",
            "GTPhysW": f"{lambda_gt_physics:.4f}",
            "Gauss": f"{gaussian_loss.item():.4f}",
            "IntLim": f"{intensity_limit_loss.item():.4f}"
        })
    
    return np.mean(losses), np.mean(ssims)

def validate(model, loader, cfg):
    model.eval()
    losses = []
    ssims = []
    
    with torch.no_grad():
        for inp, gt, names in tqdm(loader, desc="Validation"):
            inp, gt = inp.to(cfg.device), gt.to(cfg.device)
            
            pred = model(inp)
            loss = F.mse_loss(pred, gt)
            losses.append(loss.item())
            
            ssim_val = ssim(pred, gt).item()
            ssims.append(ssim_val)
    
    return np.mean(losses), np.mean(ssims)

class SimpleGTTrainConfig:
    def __init__(self, **kwargs):
        self.epochs = kwargs.get('epochs', 60)
        self.batch_size = kwargs.get('batch_size', 16)
        self.lr = kwargs.get('lr', 2e-4)
        
        # ëª¨ë¸ ì„¤ì •
        self.pred_scale = kwargs.get('pred_scale', 1.0)  # 1.0ì—ì„œ 1.5ë¡œ ì¦ê°€ (ë³´ìˆ˜ì )
        
        # GT-Physics ì„¤ì •
        self.use_gt_physics = kwargs.get('use_gt_physics', True)
        self.gt_physics_start_epoch = kwargs.get('gt_physics_start_epoch', 15)
        self.gt_physics_weight = kwargs.get('gt_physics_weight', 0.05)  # ë³´ìˆ˜ì  ì‹œì‘
        self.gt_physics_warmup = kwargs.get('gt_physics_warmup', 20)
        
        # ë¬¼ë¦¬ íŒŒë¼ë¯¸í„°
        self.background_level = kwargs.get('background_level', 0.0)
        self.air_attenuation = kwargs.get('air_attenuation', 0.01)
        
        # ê²½ë¡œ
        self.data_dir = Path(kwargs.get('data_dir', 'data'))
        self.save_dir = Path(kwargs.get('save_dir', 'checkpoints/convnext_simple_gt_exp_00'))
        
        # ë””ë°”ì´ìŠ¤
        self.device = kwargs.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')

def main():
    parser = argparse.ArgumentParser(description="ConvNeXt PGNN - Simple + GT-Physics")
    parser.add_argument("--data_dir", type=str, default="data")
    parser.add_argument("--save_dir", type=str, default="checkpoints/convnext_simple_gt_exp7")
    parser.add_argument("--epochs", type=int, default=80)
    parser.add_argument("--batch", type=int, default=16)
    parser.add_argument("--lr", type=float, default=2e-4)
    parser.add_argument("--pred_scale", type=float, default=1.0)
    
    # GT-Physics ì „ìš© ì˜µì…˜
    parser.add_argument("--use_gt_physics", action='store_true', default=True, 
                       help="Enable GT-based physics loss")
    parser.add_argument("--gt_physics_weight", type=float, default=0.2,
                       help="GT-Physics loss weight")
    parser.add_argument("--gt_physics_start_epoch", type=int, default=20,
                       help="Epoch to start GT-Physics loss")
    
    args = parser.parse_args()
    
    cfg = SimpleGTTrainConfig(
        epochs=args.epochs,
        batch_size=args.batch,
        lr=args.lr,
        pred_scale=args.pred_scale,
        use_gt_physics=args.use_gt_physics,
        gt_physics_weight=args.gt_physics_weight,
        gt_physics_start_epoch=args.gt_physics_start_epoch,
        data_dir=args.data_dir,
        save_dir=args.save_dir
    )
    
    print(f"ğŸš€ Simplified ConvNeXt PGNN Training (53M params)")
    print(f"ğŸ“ Data: {cfg.data_dir}")
    print(f"ğŸ’¾ Save: {cfg.save_dir}")
    print(f"ğŸ¯ Device: {cfg.device}")
    print(f"âš¡ Pred Scale: {cfg.pred_scale}")
    print(f"ğŸ”¬ GT-Physics: {cfg.use_gt_physics}")
    if cfg.use_gt_physics:
        print(f"   - Weight: {cfg.gt_physics_weight}")
        print(f"   - Start Epoch: {cfg.gt_physics_start_epoch}")
    print(f"ğŸ—ï¸  Architecture: Simplified (53M vs 99M original)")
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    cfg.save_dir.mkdir(parents=True, exist_ok=True)
    
    # ì„¤ì • ì €ì¥
    config_dict = {
        'epochs': cfg.epochs,
        'batch_size': cfg.batch_size,
        'lr': cfg.lr,
        'pred_scale': cfg.pred_scale,
        'use_gt_physics': cfg.use_gt_physics,
        'gt_physics_weight': cfg.gt_physics_weight,
        'gt_physics_start_epoch': cfg.gt_physics_start_epoch,
        'data_dir': str(cfg.data_dir),
        'save_dir': str(cfg.save_dir)
    }
    
    with open(cfg.save_dir / "config.json", "w") as f:
        json.dump(config_dict, f, indent=2)
    
    # ë°ì´í„° ë¡œë”
    train_ds = RadFieldDataset(cfg.data_dir / "train.npz")
    val_ds = RadFieldDataset(cfg.data_dir / "val.npz")
    
    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=4)
    
    print(f"ğŸ“Š Train: {len(train_ds)}, Val: {len(val_ds)}")
    
    # ëª¨ë¸ - ë‹¨ìˆœí™”ëœ ConvNeXt PGNN ì‚¬ìš©
    model = SimplifiedConvNeXtPGNN(in_channels=6, pred_scale=cfg.pred_scale).to(cfg.device)
    
    # ì˜µí‹°ë§ˆì´ì €
    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=1e-4)
    
    # ìŠ¤ì¼€ì¤„ëŸ¬
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=cfg.epochs, eta_min=cfg.lr * 0.1
    )
    
    best_val_ssim = 0.0
    
    print(f"\nğŸš€ Starting Simplified ConvNeXt PGNN training for {cfg.epochs} epochs...")
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ì¶œë ¥
    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"ğŸ“Š Model parameters: {total_params:,} ({total_params/1e6:.1f}M)")
    
    for epoch in range(1, cfg.epochs + 1):
        # í›ˆë ¨
        train_loss, train_ssim = train_one_epoch_simple_gt(model, train_loader, optimizer, epoch, cfg)
        
        # ê²€ì¦
        val_loss, val_ssim = validate(model, val_loader, cfg)
        
        # í•™ìŠµë¥  ì—…ë°ì´íŠ¸
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']
        
        print(f"Epoch {epoch:3d}/{cfg.epochs} | "
              f"Train: Loss={train_loss:.4f}, SSIM={train_ssim:.4f} | "
              f"Val: Loss={val_loss:.4f}, SSIM={val_ssim:.4f} | "
              f"LR={current_lr:.2e}")
        
        # ìµœê³  ëª¨ë¸ ì €ì¥
        if val_ssim > best_val_ssim:
            best_val_ssim = val_ssim
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'val_ssim': val_ssim,
                'config': config_dict
            }, cfg.save_dir / "ckpt_best.pth")
            print(f"âœ… New best SSIM: {val_ssim:.4f}")
        
        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'val_loss': val_loss,
            'val_ssim': val_ssim,
            'config': config_dict
        }, cfg.save_dir / "ckpt_last.pth")
    
    print(f"\nğŸ‰ Training completed!")
    print(f"ğŸ“ˆ Best validation SSIM: {best_val_ssim:.4f}")
    print(f"ğŸ’¾ Models saved to: {cfg.save_dir}")

if __name__ == "__main__":
    main()