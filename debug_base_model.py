#!/usr/bin/env python3
"""
ë² ì´ìŠ¤ ëª¨ë¸ ìì²´ì˜ ë¬¸ì œì  ì§„ë‹¨
ì‹¤ì œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ConvNeXt ëª¨ë¸ì˜ ì¶œë ¥ê³¼ ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ì„
"""

import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
import sys

ROOT = Path(__file__).resolve().parent
sys.path.append(str(ROOT / "src"))

from model.conv_next_pgnn import ConvNeXtUNetWithMaskAttention as ConvNeXtUNetBase
from torch.utils.data import DataLoader

# Dataset loading
class RadFieldDataset:
    def __init__(self, npz_path: Path):
        self.data = np.load(npz_path)
        if "inp" in self.data:
            self.inp = self.data["inp"].astype(np.float32)
        else:
            chans = [self.data[k].astype(np.float32)
                      for k in ["M", "mask", "logM", "X", "Y", "distance"]]
            self.inp = np.stack(chans, axis=1)
        self.gt = self.data["gt"].astype(np.float32)
        
    def get_batch(self, batch_size=2):
        """ë°°ì¹˜ ìƒ˜í”Œ ë°˜í™˜"""
        indices = np.random.choice(len(self.inp), batch_size, replace=False)
        inp_batch = torch.from_numpy(self.inp[indices])
        gt_batch = torch.from_numpy(self.gt[indices])
        return inp_batch, gt_batch

def test_model_with_different_scales():
    """ë‹¤ì–‘í•œ pred_scaleë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ” ë‹¤ì–‘í•œ pred_scaleë¡œ ë² ì´ìŠ¤ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    try:
        dataset = RadFieldDataset(Path("data/train.npz"))
        inp_batch, gt_batch = dataset.get_batch(batch_size=2)
        print(f"âœ… ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {inp_batch.shape}")
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    print(f"ì…ë ¥ í†µê³„:")
    for i in range(6):
        channel = inp_batch[:, i]
        print(f"  Ch{i}: [{channel.min().item():.3f}, {channel.max().item():.3f}] (mean: {channel.mean().item():.3f})")
    
    print(f"GT í†µê³„: [{gt_batch.min().item():.3f}, {gt_batch.max().item():.3f}] (mean: {gt_batch.mean().item():.3f})")
    print()
    
    # ë‹¤ì–‘í•œ pred_scale í…ŒìŠ¤íŠ¸
    scales = [0.1, 0.5, 1.0, 1.5, 2.0, 3.0]
    
    for scale in scales:
        print(f"ğŸ“Š pred_scale = {scale}")
        print("-" * 30)
        
        model = ConvNeXtUNetBase(in_channels=6, pred_scale=scale)
        
        # ì¶œë ¥ ë¶„ì„
        with torch.no_grad():
            output = model(inp_batch)
            
        print(f"ì¶œë ¥ í˜•íƒœ: {output.shape}")
        print(f"ì¶œë ¥ ë²”ìœ„: [{output.min().item():.6f}, {output.max().item():.6f}]")
        print(f"ì¶œë ¥ í‰ê· : {output.mean().item():.6f}")
        print(f"ì¶œë ¥ í‘œì¤€í¸ì°¨: {output.std().item():.6f}")
        
        # ê³ ìœ ê°’ ë¶„ì„
        output_flat = output.flatten().numpy()
        unique_vals = np.unique(output_flat)
        print(f"ê³ ìœ ê°’ ê°œìˆ˜: {len(unique_vals)}")
        
        if len(unique_vals) < 10:
            print(f"âš ï¸  ê³ ìœ ê°’ ìƒ˜í”Œ: {unique_vals[:5]}")
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ë¶„ì„
        model.train()
        optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
        
        optimizer.zero_grad()
        output = model(inp_batch)
        loss = nn.MSELoss()(output, gt_batch)
        loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ í†µê³„
        grad_norms = []
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_norms.append(param.grad.norm().item())
        
        total_grad = sum(grad_norms)
        avg_grad = total_grad / len(grad_norms) if grad_norms else 0.0
        
        print(f"ì†ì‹¤: {loss.item():.6f}")
        print(f"ì´ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„: {total_grad:.6f}")
        print(f"í‰ê·  ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„: {avg_grad:.2e}")
        
        if avg_grad < 1e-8:
            print("ğŸš¨ ê·¸ë˜ë””ì–¸íŠ¸ ì†Œë©¸!")
        elif len(unique_vals) < 10:
            print("ğŸš¨ ì¶œë ¥ saturation!")
        else:
            print("âœ… ì •ìƒ ë™ì‘")
        
        print()

def analyze_model_components():
    """ëª¨ë¸ êµ¬ì„±ìš”ì†Œë³„ ë¶„ì„"""
    print("ğŸ” ëª¨ë¸ êµ¬ì„±ìš”ì†Œë³„ ë¶„ì„")
    print("=" * 60)
    
    # ì‹¤ì œ ë°ì´í„° ë¡œë“œ
    try:
        dataset = RadFieldDataset(Path("data/train.npz"))
        inp_batch, gt_batch = dataset.get_batch(batch_size=2)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    model = ConvNeXtUNetBase(in_channels=6, pred_scale=1.0)
    
    # Hookìœ¼ë¡œ ì¤‘ê°„ ì¶œë ¥ ìº¡ì²˜
    activations = {}
    
    def save_activation(name):
        def hook(module, input, output):
            if isinstance(output, torch.Tensor):
                activations[name] = output.detach()
        return hook
    
    # ì£¼ìš” ë ˆì´ì–´ì— hook ë“±ë¡
    model.convnext.stem.register_forward_hook(save_activation('stem'))
    model.convnext.stages[0].register_forward_hook(save_activation('stage0'))
    model.convnext.stages[1].register_forward_hook(save_activation('stage1'))
    model.convnext.stages[2].register_forward_hook(save_activation('stage2'))
    model.convnext.stages[3].register_forward_hook(save_activation('stage3'))
    
    if hasattr(model, 'decoder_head'):
        model.decoder_head.register_forward_hook(save_activation('decoder_head'))
    
    # Forward pass
    with torch.no_grad():
        output = model(inp_batch)
    
    print("ì¤‘ê°„ activation ë¶„ì„:")
    for name, activation in activations.items():
        act_flat = activation.flatten()
        unique_vals = len(torch.unique(act_flat))
        
        print(f"{name:15} - Shape: {str(activation.shape):20} | "
              f"Range: [{activation.min().item():.4f}, {activation.max().item():.4f}] | "
              f"Unique: {unique_vals:6} | "
              f"Std: {activation.std().item():.4f}")
        
        if unique_vals < 10:
            print(f"  âš ï¸  {name}ì—ì„œ saturation ë°œìƒ!")
    
    print(f"\nìµœì¢… ì¶œë ¥:")
    print(f"Range: [{output.min().item():.6f}, {output.max().item():.6f}]")
    print(f"Unique values: {len(torch.unique(output.flatten()))}")

def main():
    print("ğŸš¨ ë² ì´ìŠ¤ ëª¨ë¸ ë¬¸ì œ ì§„ë‹¨")
    print("=" * 60)
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
    model = ConvNeXtUNetBase(in_channels=6, pred_scale=1.0)
    
    print("ëª¨ë¸ íŒŒë¼ë¯¸í„° í†µê³„:")
    total_params = 0
    zero_params = 0
    
    for name, param in model.named_parameters():
        param_count = param.numel()
        param_zeros = (param == 0).sum().item()
        total_params += param_count
        zero_params += param_zeros
        
        if param_count < 100:  # ì‘ì€ íŒŒë¼ë¯¸í„°ë§Œ ì¶œë ¥
            print(f"{name:30} - Shape: {str(param.shape):15} | "
                  f"Range: [{param.min().item():.4f}, {param.max().item():.4f}] | "
                  f"Zeros: {param_zeros}/{param_count}")
    
    print(f"\nì´ íŒŒë¼ë¯¸í„°: {total_params:,}")
    print(f"0ì¸ íŒŒë¼ë¯¸í„°: {zero_params:,} ({100*zero_params/total_params:.1f}%)")
    
    print("\n" + "="*60)
    test_model_with_different_scales()
    
    print("="*60)
    analyze_model_components()

if __name__ == "__main__":
    main()